{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excel Data Extractor \n",
    "\n",
    "This function extracts all column headers for all visible sheets from a list of excel files.\n",
    "\n",
    "Requirements: Run function in folder containing the source folder.\n",
    "\n",
    "Usage: ExtractExcelData(source_folder=None)\n",
    "\n",
    "Output: Creates a folder (named \"Extracted_Fields\") of excel files with each file listing sheetnames (Column A) and associated column headers (Column B)\n",
    "\n",
    "Return: (source_folder, merged_df_dict): tuple of Source folder name (string) and dictionary of merged dataframes for each source excel file\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractExcelData(source_folder):\n",
    "                     \n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import re\n",
    "    import pickle\n",
    "    \n",
    "    if source_folder==None:\n",
    "        print('Missing source_folder input!')\n",
    "        return None    \n",
    "    \n",
    "    cwd=os.getcwd()\n",
    "    # List all files to extract\n",
    "    files=[]\n",
    "    for file in os.listdir(os.path.join(cwd,source_folder)):\n",
    "        if '.xlsx'in file:\n",
    "            files.append(file)\n",
    "    #print(files)\n",
    "    \n",
    "    # Access source folder\n",
    "    regex=re.compile(r'.*\\\\{0}$'.format(source_folder))\n",
    "    if bool(regex.match(os.getcwd()))==False:\n",
    "        os.chdir('.\\\\{0}'.format(source_folder))\n",
    "    \n",
    "    merged_df_dict=dict()\n",
    "    # Loop through all .xlsx files\n",
    "    for i, file in enumerate(files):\n",
    "        filename=file\n",
    "        \n",
    "        try:\n",
    "            a=0\n",
    "            # Retrieve sheets from file and store sheetnames in list\n",
    "            sourcefile_name=filename\n",
    "            a=1\n",
    "            wb=pd.ExcelFile(sourcefile_name)\n",
    "            sourcefile_shts=wb.book.sheets()\n",
    "            a=2\n",
    "            # Extract information from all sheets. Header is a multiindex\n",
    "            sourcefile_dfs=[]\n",
    "            print('\\nExtracting File {0}/{1} - {2}'.format(i+1,len(files),filename))\n",
    "            for sht in sourcefile_shts:\n",
    "                if sht.visibility == 1 or sht.visibility == 2:\n",
    "                    continue            \n",
    "                print('Extracting {}'.format(sht.name))\n",
    "                sourcefile_df=pd.read_excel(wb,sheet_name=sht.name,header=0, keep_default_na=False)\n",
    "                sourcefile_df=sourcefile_df.groupby(sourcefile_df.columns[0]).agg(lambda x: ', '.join(set(x.astype(str))))\n",
    "                sourcefile_df_cols=sourcefile_df.columns.tolist()\n",
    "                multi_idx=pd.MultiIndex.from_product([[sht.name],sourcefile_df_cols])\n",
    "                sourcefile_df.columns=multi_idx\n",
    "                sourcefile_dfs.append(sourcefile_df) \n",
    "            a=3\n",
    "            # Merge all sheets into single df\n",
    "            #print('Merging sheet {0}/{1}'.format(2,len(sourcefile_dfs)))\n",
    "            merged_df=sourcefile_dfs[0].merge(sourcefile_dfs[1],left_index=True,right_index=True,how='outer')\n",
    "            for i in range(2,len(sourcefile_dfs)):\n",
    "                #print('Merging sheet {0}/{1}'.format(i+1,len(sourcefile_dfs))) \n",
    "                merged_df=merged_df.merge(sourcefile_dfs[i],left_index=True,right_index=True,how='outer')\n",
    "\n",
    "            # Rename index\n",
    "            merged_df.index.rename('SPEC ID', inplace=True)\n",
    "            merged_df_dict[sourcefile_name]=merged_df\n",
    "            \n",
    "            a=4\n",
    "            # Create df to store headers\n",
    "            fields=merged_df.columns.tolist()\n",
    "            fields_df=pd.DataFrame(fields,columns=['Sheet Name','Column Name'])\n",
    "            fields_df['Template Column Name']=\"\"\n",
    "\n",
    "            # Create folder to store excel files\n",
    "            regex3=re.compile(r'.*\\\\Extracted_Fields$')\n",
    "            #If not in Extracted_Fields folder already\n",
    "            if bool(regex3.match(os.getcwd()))==False:\n",
    "                if 'Extracted_Fields' not in os.listdir():\n",
    "                        os.mkdir('.\\\\Extracted_Fields')\n",
    "                        os.chdir('.\\\\Extracted_Fields')\n",
    "                else:    \n",
    "                    os.chdir('.\\\\Extracted_Fields')\n",
    "\n",
    "            # Write extracted fields into destination folder\n",
    "            writer = pd.ExcelWriter(\"{0}_Extracted_Fields.xlsx\".format(os.path.splitext(filename)[-2]), engine='xlsxwriter')\n",
    "            sheetname='Extracted Fields'\n",
    "            fields_df.to_excel(writer, sheet_name=sheetname,index=False)  # send df to writer\n",
    "            worksheet = writer.sheets[sheetname]  # pull worksheet object\n",
    "\n",
    "            for idx, col in enumerate(fields_df):  # loop through all columns\n",
    "                    series = fields_df[col]\n",
    "                    max_len = max((\n",
    "                        series.astype(str).map(len).max(),  # len of largest item\n",
    "                        len(str(series.name))  # len of column name/header\n",
    "                        )) + 1  # adding a little extra space\n",
    "                    worksheet.set_column(idx, idx, max_len)  # set column width .set_column(first_col, last_col, width, cell_format, options)\n",
    "            writer.save()\n",
    "            os.chdir(os.path.join(cwd,source_folder))\n",
    "            print(\"File created! - {0}_Extracted_Fields.xlsx\".format(os.path.splitext(filename)[-2]))\n",
    "\n",
    "        except:\n",
    "            #files.clear()\n",
    "            os.chdir(cwd)\n",
    "            print('Error detected while extracting file {0} - {1}\\nFailed at Step {2}'.format(i+1,file,a))\n",
    "            return None\n",
    "      \n",
    "    #Back to starting point\n",
    "    os.chdir(cwd)\n",
    "    \n",
    "    #Write merged_df_dict into pickle file\n",
    "    with open('ExtractExcelDataObjects.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "        pickle.dump([source_folder,merged_df_dict], f)\n",
    "    \n",
    "    print(\"\\nFields extracted!\")\n",
    "    return (source_folder, merged_df_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting File 1/6 - pc paperboard (1).xlsx\n",
      "Extracting Header Information\n",
      "Extracting Identifiers_01\n",
      "Extracting Material Assignment_02\n",
      "Extracting PMAT\n",
      "Extracting Classification_09\n",
      "Extracting Material Compliance_10\n",
      "Extracting Buy Menu Card_11\n",
      "Extracting Pack Technologies_12\n",
      "Extracting Standard Component Type_13\n",
      "Extracting Dimensions (3D Outside)_15\n",
      "Extracting Dimensions (3D Inside)_16\n",
      "Extracting Dimensions 3DCrease Line Dim_17\n",
      "Extracting Flat Blank Size_18\n",
      "Extracting Technology_19\n",
      "Extracting Conversion Factor for Piece_20\n",
      "Extracting Storage_21\n",
      "Extracting Delivery_22\n",
      "Extracting Product Contact_23\n",
      "File created! - pc paperboard (1)_Extracted_Fields.xlsx\n",
      "\n",
      "Extracting File 2/6 - pc-corrugated.xlsx\n",
      "Extracting Header Information\n",
      "Extracting Identifiers_01\n",
      "Extracting Material Assignment_02\n",
      "Extracting Specification Inherits From_03\n",
      "Extracting Buy Menu Card_10\n",
      "Extracting Pack Technologies_11\n",
      "Extracting Standard Component Type_12\n",
      "Extracting Dimensions (3D Outside)_14\n",
      "Extracting Dimensions (3D Inside)_15\n",
      "Extracting Dimensions 3DCrease Line Dim_16\n",
      "Extracting Flat Blank Size_17\n",
      "Extracting CaliperThickness_18\n",
      "Extracting Technology_19\n",
      "Extracting Fefco Code_Include in Mass shee\n",
      "Extracting Conversion Factor for Piece_21\n",
      "Extracting ECT_INCLUDE in the Mass sheet\n",
      "Extracting Safety Factor_include in Mass \n",
      "Extracting BCRCompression Cal INCLUDE in M\n",
      "Extracting BCTCompression Strength INCLUDE\n",
      "Extracting Storage_27\n",
      "Extracting Delivery_28\n",
      "Extracting Safety Limitations_29\n",
      "Extracting Product Contact_30\n",
      "File created! - pc-corrugated_Extracted_Fields.xlsx\n",
      "\n",
      "Extracting File 3/6 - pc-flexible.xlsx\n",
      "Extracting Header Information\n",
      "Extracting Identifiers_01\n",
      "Extracting Material Assignment_02\n",
      "Extracting PMATS\n",
      "Extracting Material Governance Class_08\n",
      "Extracting Classification_09\n",
      "Extracting Material Compliance_10\n",
      "Extracting Buy Menu Card_11\n",
      "Extracting Pack Technologies_12\n",
      "Extracting Standard Component Type_13\n",
      "Extracting Core Size_15\n",
      "Extracting Width_16\n",
      "Extracting Cut Off_17\n",
      "Extracting Count_18\n",
      "Extracting Area_19\n",
      "Extracting Edge aligment_20\n",
      "Extracting Roll Diameter_21\n",
      "Extracting Conversion Factor for Piece_22\n",
      "Extracting Other_23\n",
      "Extracting Converting_24\n",
      "Extracting Product Contact_25\n",
      "Extracting Receiving Requirements_26\n",
      "File created! - pc-flexible_Extracted_Fields.xlsx\n",
      "\n",
      "Extracting File 4/6 - pc-injebm.xlsx\n",
      "Extracting Header Information\n",
      "Extracting Identifiers_01\n",
      "Extracting Material Assignment_02\n",
      "Extracting PMAT\n",
      "Extracting Classification_08\n",
      "Extracting Buy Menu Card_09\n",
      "Extracting Standard Component Type_10\n",
      "Extracting Dimensions_12\n",
      "Extracting Conversion Factor for Piece_13\n",
      "Extracting Inbound Receiving Requiremen_14\n",
      "Extracting SPIMaterial Identification c_17\n",
      "File created! - pc-injebm_Extracted_Fields.xlsx\n",
      "\n",
      "Extracting File 5/6 - pc-metal.xlsx\n",
      "Extracting Header Information\n",
      "Extracting Identifiers_01\n",
      "Extracting Material Assignment_SAP P Codes\n",
      "Extracting PMAT\n",
      "Extracting Classification_08\n",
      "Extracting Buy Menu Card_09\n",
      "Extracting Pack Technologies_10\n",
      "Extracting Dimensions_13\n",
      "Extracting Conversion Factor for Piece_14\n",
      "Extracting Inbound Receiving Requiremen_15\n",
      "File created! - pc-metal_Extracted_Fields.xlsx\n",
      "\n",
      "Extracting File 6/6 - Thermo PC sheet.xlsx\n",
      "Extracting Header Information\n",
      "Extracting Identifiers_01\n",
      "Extracting Material Assignment_SAP PC\n",
      "Extracting PMAT\n",
      "Extracting Classification_08\n",
      "Extracting Buy Menu Card_09\n",
      "Extracting Pack Technologies_10\n",
      "Extracting Standard Component Type_11\n",
      "Extracting Allergens_12\n",
      "Extracting Dimensions_13\n",
      "Extracting Conversion Factor for Piece_14\n",
      "Extracting Inbound Receiving Requiremen_16\n",
      "Extracting SPIMaterial Identification c_19\n",
      "File created! - Thermo PC sheet_Extracted_Fields.xlsx\n",
      "\n",
      "Fields extracted!\n"
     ]
    }
   ],
   "source": [
    "source_folder, merged_df_dict=ExtractExcelData(source_folder='Source Folder')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
